{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOtV2J2CCeEp"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "driver_locations = \"/content/gdrive/MyDrive/week_8_data/driver_locations_during_request.csv\"\n",
        "data = \"/content/gdrive/MyDrive/week_8_data/data_cleaning.csv\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df= pd.read_csv(data)"
      ],
      "metadata": {
        "id": "GHT9GSfnDNf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Split Data into Training and Hold-out Set**\n",
        "First, split your dataset into a training set and a hold-out set. This allows us to train our causal model on one part and evaluate interventions and machine learning models on the other."
      ],
      "metadata": {
        "id": "Z9dxad4AC0lz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# we use trip_distance_km as our  target variable\n",
        "X = df.drop(columns=['trip_distance_km'])\n",
        "y = df['trip_distance_km']\n",
        "\n",
        "X_train, X_holdout, y_train, y_holdout = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "NbTfS99TC_V8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create a Causal Graph using all Training Data**\n",
        "Use a causal inference library like pgmpy to create a causal graph from your training data. This graph represents the causal relationships among variables."
      ],
      "metadata": {
        "id": "BZKPiIuUEDiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pgmpy"
      ],
      "metadata": {
        "id": "EL7N9bVMESvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pgmpy.estimators import PC\n",
        "from pgmpy.base.DAG import DAG\n",
        "\n",
        "# Example: Using PC algorithm to estimate the causal graph (replace with your method)\n",
        "model = PC(data=X_train)\n",
        "causal_graph = model.estimate(return_type='dag')\n"
      ],
      "metadata": {
        "id": "2GONsNQuD59C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create New Causal Graphs with Increasing Fractions of the Data and Compare**\n",
        "Generate causal graphs using increasing fractions of the training data and compare them with the ground truth graph using Jaccard Similarity Index."
      ],
      "metadata": {
        "id": "v17vilM_EkBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pgmpy.estimators import PC\n",
        "from pgmpy.base.DAG import DAG\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "def calculate_jaccard_similarity(graph1, graph2):\n",
        "    # Convert graphs to sets of edges\n",
        "    edges1 = set(graph1.edges())\n",
        "    edges2 = set(graph2.edges())\n",
        "\n",
        "    # Calculate Jaccard Similarity Index\n",
        "    intersection = len(edges1.intersection(edges2))\n",
        "    union = len(edges1.union(edges2))\n",
        "    return intersection / union if union != 0 else 0.0\n",
        "\n",
        "# Initialize variables\n",
        "jaccard_scores = []\n",
        "num_iterations = 10  # Example: 10 iterations with increasing fractions\n",
        "\n",
        "for i in range(1, num_iterations + 1):\n",
        "    # Shuffle and select a fraction of the training data\n",
        "    fraction_size = i / num_iterations\n",
        "    shuffled_data = shuffle(X_train)\n",
        "    split_index = int(len(shuffled_data) * fraction_size)\n",
        "    fraction_data = shuffled_data.iloc[:split_index]\n",
        "\n",
        "    # Learn causal graph using PC algorithm\n",
        "    model_fraction = PC(data=fraction_data)\n",
        "    causal_graph_fraction = model_fraction.estimate(return_type='dag')\n",
        "\n",
        "    # Calculate Jaccard Similarity with ground truth graph\n",
        "    jaccard_score = calculate_jaccard_similarity(causal_graph, causal_graph_fraction)\n",
        "    jaccard_scores.append(jaccard_score)\n",
        "\n",
        "# Plotting Jaccard Similarity Scores\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(np.arange(1, num_iterations + 1), jaccard_scores, marker='o')\n",
        "plt.xlabel('Fraction of Data Used')\n",
        "plt.ylabel('Jaccard Similarity Index')\n",
        "plt.title('Comparison of Causal Graphs with Increasing Data Fractions')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "C4zebr_nEs3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # **Select Variables Pointing Directly to the Target Variable**\n",
        "After identifying a stable causal graph (you can choose based on Jaccard similarity stability or other criteria), select variables that directly influence the target variable for intervention analysis."
      ],
      "metadata": {
        "id": "4Vm4iuw6E4aP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pgmpy.inference import Inference\n",
        "\n",
        "# Example: Selecting variables directly pointing to the target variable 'trip_distance_km'\n",
        "direct_causes = list(causal_graph.predecessors('trip_distance_km'))\n",
        "\n",
        "# Print or use these variables for further analysis or interventions\n",
        "print(\"Variables directly pointing to 'trip_distance_km':\", direct_causes)\n"
      ],
      "metadata": {
        "id": "eKBMLEO9FDjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Answer Intervention Questions using Do-Operations**\n",
        "Use do-operations (interventions) based on the causal graph to answer specific questions about interventions."
      ],
      "metadata": {
        "id": "4cXXP_raFYE8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Interventions based on the causal graph\n",
        "infer = Inference(causal_graph)\n",
        "# specific interventions and queries as per our questions\n",
        "result_i = infer.query(variables=['unfulfilled_requests'], do={'drivers_movement': 'recommended'})\n",
        "result_ii = infer.query(variables=['unfulfilled_requests'], do={'location_accuracy': '20%'})\n",
        "result_iii = infer.query(variables=['completed_orders'], do={'time_requirements': 'changed'})\n",
        "result_iv = infer.query(variables=['completed_orders'], do={'drivers_increase': '10%'})\n",
        "\n",
        "# Print or use the results as needed\n",
        "print(\"Effect on number of unfulfilled requests with recommended driver movement:\", result_i)\n",
        "print(\"Effect on number of unfulfilled requests with 20% location accuracy:\", result_ii)\n",
        "print(\"Fraction of orders completed with changed time requirements:\", result_iii)\n",
        "print(\"Fraction of orders completed with 10% increase in drivers:\", result_iv)\n"
      ],
      "metadata": {
        "id": "QWm0qEQOFkUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train ML Models and Evaluate Overfitting**\n",
        "Finally, train machine learning models using all variables and only the variables selected by the causal graph. Evaluate each model's performance and overfitting using a hold-out set."
      ],
      "metadata": {
        "id": "KjpI5EHZFqEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Example: Train models using all variables and selected variables\n",
        "def train_and_evaluate(X_train, X_holdout, y_train, y_holdout):\n",
        "    # Model using all variables\n",
        "    model_all = RandomForestClassifier(random_state=42)\n",
        "    model_all.fit(X_train, y_train)\n",
        "    y_pred_all = model_all.predict(X_holdout)\n",
        "    acc_all = accuracy_score(y_holdout, y_pred_all)\n",
        "\n",
        "    # Model using selected variables from causal graph\n",
        "    selected_features = direct_causes  # Example: Use variables directly pointing to target\n",
        "    X_train_selected = X_train[selected_features]\n",
        "    X_holdout_selected = X_holdout[selected_features]\n",
        "\n",
        "    model_selected = XGBClassifier(random_state=42)\n",
        "    model_selected.fit(X_train_selected, y_train)\n",
        "    y_pred_selected = model_selected.predict(X_holdout_selected)\n",
        "    acc_selected = accuracy_score(y_holdout, y_pred_selected)\n",
        "\n",
        "    return acc_all, acc_selected\n",
        "\n",
        "# Example usage\n",
        "accuracy_all, accuracy_selected = train_and_evaluate(X_train, X_holdout, y_train, y_holdout)\n",
        "print(f\"Accuracy of model using all variables: {accuracy_all:.4f}\")\n",
        "print(f\"Accuracy of model using selected variables: {accuracy_selected:.4f}\")\n"
      ],
      "metadata": {
        "id": "RFHD_-5vF1Bu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}